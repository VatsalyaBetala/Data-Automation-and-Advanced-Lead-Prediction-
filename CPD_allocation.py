# -*- coding: utf-8 -*-
"""Vatsalya | Voiro | Myntra CPD Allocation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GxlcqmRcRYrRWe7hpmdXM8hFyoLIRGIE

# Importation and Uploadation

Approach :
*   Upload the Myntra Allocation Sheet here (as a **.xlxs** format)
*   Upload the Master Mapping Sheet (with the correct names) if needed so.
"""

#@title Upload the datas
from google.colab import files
import pandas as pd
import random as rd
uploaded = files.upload()
filename = next(iter(uploaded))
print(filename)

#@title Reading Data
#Importing the Data
path = "Myntra Allocation Events.xlsx"
xl = pd.ExcelFile(path)
df_weight = xl.parse("BU Targets")
df_rates = xl.parse("rate")
df_imps = xl.parse("Event Impresseions")

df_weight["weight"] = df_weight["weight"] * 100

#Renaming the first column to Page
df_imps.rename(columns = {"Unnamed: 0" : "Page"}, inplace = True)
df_imps.drop("Unnamed: 8", axis=1, inplace=True)
df_imps.dropna(how="all", inplace=True)
df_imps.reset_index(drop=True, inplace=True)

#BU NAMES
bu_names = df_weight["BU"].unique()

df_weight.head()

"""# Ingestable Data

NOTE : This draft of the data is inputted with **Supply for each property manually**. In order to extract it from the column itself, kindly consult a python engineer and get the last few lines removed.
"""

#@title Raw Data -  BU(s)
import pandas as pd

#BU NAMES
bu_names = df_weight["BU"].unique()

new_df = pd.DataFrame(columns=['Event', 'Day', 'Page', 'Property', 'BU'])

for i in df_imps["Date"].unique() :
  for day in df_imps.columns[2:-1]:

      filtered_df = df_imps[(df_imps['Date'] == i)][['Page', 'Date', day]]

      rows = []
      for _, row in filtered_df.iterrows():
          for bu_name in bu_names:
              new_row = {
                  'Event': 'MFC',
                  'Day': day,
                  'Page': row['Page'],
                  'Property': row['Date'],
                  'BU': bu_name
              }
              rows.append(new_row)

      new_df = pd.concat([new_df, pd.DataFrame(rows)])

#Adding Supply
new_df["Supply"] = 0

#Top Brands
new_df.loc[new_df["Property"] == "Top brands (15 Brand Tiles)", "Supply"] = 15

#New Widget 2.1
new_df.loc[new_df["Property"] == "New widget 2.1", "Supply"] = 10

#Widgets - Platinum, Gold, Bronze, Silver
list_widget = ["Platinum", "Gold", "Bronze", "Silver"]

for i in list_widget :
  new_df.loc[new_df["Property"] == i, "Supply"] = 10

#Scrollable Widgets (MP-3 and WP-3)
list_1 = ["Scrollable Widget (MP-3)", "Scrollable Widget (WP-3)"]

for j in list_1 :
  new_df.loc[new_df["Property"] == j, "Supply"] = 3

#Scrollable Widgets (MP-7 and WP-7)
list_2 = ['Scrollable Widget (MP-7)','Scrollable Widget (MP-7)']

for j in list_2 :
  new_df.loc[new_df["Property"] == j, "Supply"] = 7



print(new_df.head())

"""# Weigtage Adjustments"""

#@title Adding BU Weigth(s) and Allocation (rawly calculated)

weight_by_Page_BU = df_weight[['Page', 'BU', 'weight']].copy()

weight_by_Page_BU.columns = ['Page', 'BU', 'BU_Weight']

new_df = pd.merge(new_df, weight_by_Page_BU, on=['Page', 'BU'], how='left')

#new_df['BU_Weight'] = new_df['BU_Weight'].str.replace('%', '')

new_df['BU_Weight'] = pd.to_numeric(new_df['BU_Weight'], errors='coerce')

new_df['Allocation'] = new_df['Supply'] * new_df['BU_Weight'] / 100

new_df['Allocation'] = new_df['Allocation']

new_df.head()

"""# Adding Impressions (divided equally by supply)"""

import numpy as np

# Assuming new_df is your current DataFrame and df_imps is the previous DataFrame with impressions

# Create a new 'Impression' column in new_df
new_df['Impression'] = 0

# Iterate through each unique property in new_df
for property_name in new_df['Property'].unique():
    # Filter new_df for the current property
    property_df = new_df[new_df['Property'] == property_name]

    # Iterate through each row in the filtered property_df
    for index, row in property_df.iterrows():
        page = row['Page']
        day = row['Day']
        supply = row['Supply']

        # Filter df_imps to find the corresponding row based on page and day
        matching_row = df_imps[(df_imps['Page'] == page) & (df_imps['Date'] == property_name)]

        # Check if matching_row is not empty
        if not matching_row.empty:
            impressions = matching_row[day].values[0]

            # Calculate the impression per allocation, handling division by zero or infinity
            if supply == 0:
                impression_per_allocation = np.inf  # Set to infinity
            else:
                impression_per_allocation = (impressions * 1000000) / supply

            # Check if the calculated value is finite
            if np.isfinite(impression_per_allocation):
                # Update the 'Impression' column in new_df with the impression per allocation for the matching rows
                new_df.loc[(new_df['Day'] == day) & (new_df['Page'] == page) & (new_df['Property'] == property_name), 'Impression'] = round(impression_per_allocation)

# Print the updated new_df
print(new_df)

new_df.head()

"""The code snippet below, it for removing NULL line items from the ingestable data (run only if required)"""

#@title Dropping null values
# Drop rows with NaN values in Allocation column
new_df.dropna(subset=['Allocation'], inplace=True)

# Remove rows where Allocation is 0
new_df = new_df.query('Allocation != 0')

# Print the updated new_df
print(new_df)

"""# Rounding Algorithm

This script is the **potential rounding algorithm**, which basically rounds off the raw, calculated supply into definite slots while making sure the total supply equated the supply.
"""

import math
import pandas as pd

def round_allocations(df, day, page, prop):
    test_df = df[(df['Day'] == day) & (df['Page'] == page) & (df['Property'] == prop)]

    if test_df.shape[0] != 0:

        # Filter rows for the specified day, page, and property
        filtered_indices = test_df.index

        # Extract the decimal allocations column
        decimal_allocations = df.loc[filtered_indices, 'Allocation'].tolist()

        # Round each decimal allocation to the nearest whole number
        rounded_allocations = [math.floor(allocation) for allocation in decimal_allocations]

        rounded_total = sum(rounded_allocations)

        supply = df.loc[df['Property'] == prop, 'Supply'].iloc[0]
        rounding_adjustment = supply - rounded_total

        if rounded_total > supply:
            rounding_adjustment = 0

        # Sort the allocations by their fractional parts
        sorted_indices = sorted(range(len(decimal_allocations)), key=lambda i: decimal_allocations[i] % 1, reverse=True)

        # Adjust the allocations to compensate
        for i in range(abs(rounding_adjustment)):
            index = sorted_indices[i % len(sorted_indices)]
            rounded_allocations[index] += int(math.copysign(1, rounding_adjustment))

        # Update the 'New Allocation' column
        df.loc[filtered_indices, 'New Allocation'] = rounded_allocations

    return df

"""The code snippet below is for running the rounding algorithm through the ingestable data."""

# @title Running the Algorithm

#Unique Properties
for prop in new_df["Property"].unique() :
#Unique Days
  for i in new_df["Day"].unique() :
#Unique Page
    for j in new_df["Page"].unique() :
        new_df = round_allocations(new_df, i, j, prop)
new_df.head()

"""# Calculating Rates"""

for index, row in new_df.iterrows():
    page = row['Page']
    prop = row['Property']
# Create the new property name with the 'Page_Property Name' format
    new_prop = f"{page}_{prop}"
    new_df.at[index, 'Property'] = new_prop

#@title Mapping the correct names.
df_map = pd.read_csv("Myntra Master Data Sheet - Mapping Keys (1).csv")

for index, row in df_map.iterrows():
    property_name = row['Property Names']
    correct_name_1 = row['Correct Names.1']

    new_df['Property'] = new_df['Property'].replace(property_name, correct_name_1)

for index, row in df_map.iterrows() :
  bu_name = row["BU Allocation "]
  correct_name_2 = row["Correct Names"]

  new_df["BU"] = new_df["BU"].replace(bu_name, correct_name_2)

for index, row in df_map.iterrows() :
  page_name = row["Page Name"]
  correct_name_3 = row["Short Forms"]

  new_df["Page"] = new_df["Page"].replace(page_name, correct_name_3)

#@title Mapping the right names (in df_rates)

for index, row in df_map.iterrows():
    property_name = row['Property Names']
    correct_name_1 = row['Correct Names.1']
    df_rates['Property'] = df_rates['Property'].replace(property_name, correct_name_1)



#@title Calculating the rates and ingesting in the data (new_df)
new_df["Rate"] = 0
for index, row in new_df.iterrows():
    property_name = row['Property']
    matching_row = df_rates[df_rates['Property'] == property_name]

    if not matching_row.empty:
        bau_rate_ops = matching_row['BAU RATE - OPS '].iloc[0]
        rate = bau_rate_ops * (row['Impression'] / 1000)
        new_df.loc[index, 'Rate'] = rate

"""# Conventional Name Mapping (acc. to Master Sheet)

# Downloading the ingestable data

IMPORTANT: **MAKE SURE YOU DOWNLOAD THE DATA BEFORE CLOSING THE TAB**. There are high chances of losing the data.
"""

#Downloading
from google.colab import files
new_df.to_excel("export 19 (Potential Churns).xlsx", index = False)
files.download("export 19 (Potential Churns).xlsx")

"""# UI Filter Tab"""

import pandas as pd
import ipywidgets as widgets
from IPython.display import display, clear_output

day_dropdown = widgets.SelectMultiple(options=["Day1", "Day2", "Day3", "Day4", "Day5", "Day6"], description="Day:")
page_dropdown = widgets.SelectMultiple(options=["MP", "HP", "WP"], description="Page:")
property_dropdown = widgets.SelectMultiple(options=new_df["Property"].unique(), description="Property:")
bu_dropdown = widgets.SelectMultiple(options=new_df["BU"].unique(), description="BU:")

filter_button = widgets.Button(description="Filter")
reset_button = widgets.Button(description="Reset")

output = widgets.Output()

def filter_button_clicked(button):
    selected_days = day_dropdown.value
    selected_pages = page_dropdown.value
    selected_property = property_dropdown.value
    selected_bu = bu_dropdown.value

    subset = new_df[(new_df["Day"].isin(selected_days)) &
                    (new_df["Page"].isin(selected_pages)) &
                    (new_df["Property"].isin(selected_property)) &
                    (new_df["BU"].isin(selected_bu))]

    with output:
        clear_output()

        display(subset)

def reset_button_clicked(button):
    day_dropdown.value = ()
    page_dropdown.value = ()
    property_dropdown.value = None
    bu_dropdown.value = ()

    with output:
        clear_output()

filter_button.on_click(filter_button_clicked)
reset_button.on_click(reset_button_clicked)

display(day_dropdown, page_dropdown, property_dropdown, bu_dropdown, filter_button, reset_button)
display(output)